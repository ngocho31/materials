\chapter{Các công trình liên quan}

\section{Các công trình nghiên cứu liên quan đến Chatbot hỗ trợ
thương mại điện tử}

\subsection{Bài báo về Chatbot hỗ trợ y tế tự động}
Đây là bài báo có tên \textit{Automated Medical Chatbot}
\cite{automatedmedical}. Trong bài báo này, tác giả đề xuất một
hệ thống có khả năng đặt ra nhiều câu hỏi cho người dùng cho đến khi
xác định được căn bệnh mà người dùng đang gặp phải. Đây gần như là
một hệ thống tư vấn y tế. Hệ thống sẽ thu thập các thông tin từ
người dùng như triệu chứng, sau đó đưa ra những căn bệnh mà
người dùng có thể mắc phải và hỏi người dùng về cảm giác của họ.
Sau khi nhận được nhiều dữ liệu, nó sẽ tìm ra căn bệnh
có khả năng xảy ra nhất.

Ngoài ra, họ đặt ra một khái niệm mức ngưỡng giúp phát hiện mức độ
của vấn đề. Tuỳ vào mức độ nghiêm trọng của bệnh mà nó sẽ đề xuất
các biện pháp khắc phục và thuốc cho người dùng hoặc kết nối
người dùng với bác sĩ.

Trong bài báo, tác giả đã sử dụng phương pháp AIML (Artificial
Intelligence Mark-up Lang\-uage) để hiểu được các mẫu (pattern)
trong tin nhắn của người dùng thông qua các thẻ (tag)
được xác định trước.

Ví dụ, ta có một số các \textit{pattern tag} được xác định
trước như ví dụ \ref{exam:pattern}. Khi người dùng nói
\enquote{I am suffering from headache.} (Tôi đang bị đau đầu),
hệ thống sẽ ánh xạ tin nhắn của người dùng với các pattern
và phát hiện trùng với pattern \enquote{I am suffering from *},
\enquote{headache}
(đau đầu) sẽ được thay thế bởi dấu *. Sau đó hệ thống sẽ truy cập
vào cơ sở dữ liệu với thông tin đầu tiên là triệu chứng đau đầu
và đưa ra hành động tiếp theo.

\renewcommand{\textboxenvname}{Ví dụ}
\begin{textbox}[exam:pattern]{Một số các pattern tag}
\begin{Verbatim}[breaklines=true, breakanywhere=true]
<pattern>I am feeling like *</pattern>
<pattern>I am having *</pattern>
<pattern>I am suffering from *</pattern>
\end{Verbatim}
\end{textbox}

Cùng với một số các thành phần khác thì hệ thống của họ đưa ra có thể
tư vấn khách hàng như ví dụ \ref{exam:medicaldialog}. Đầu tiên có thể
thực hiện với câu chào hỏi, và hỏi về vấn đề của người dùng. Sau khi
nhận được thông tin về triệu chứng là đau đầu, Chatbot sẽ hỏi thêm các
thông tin triệu chứng khác để làm rõ căn bệnh. Cuối cùng sau khi lấy
đủ thông tin, Chatbot đưa ra kết luận về căn bệnh người dùng mắc phải
và cách chữa trị.

\renewcommand{\textboxenvname}{Ví dụ}
\begin{textbox}[exam:medicaldialog]{Một mẫu hội thoại của Chatbot}
\begin{Verbatim}[breaklines=true, breakanywhere=true]
User: Hello
Chatbot: Hi there, tell me how can I help you?
User: I am having an Headache
Chatbot: Are you having pain in your eyes?
User: Yes
Chatbot: Do you feel like vomiting?
User: yes I do
Chatbot: I think you are most likely having a migraine attack
Chatbot: Taking "ibuprofen" 2 tablets would reduce pain in you eyes. Also take "aspirin" 20ml to help you tackle vomiting. Do take a nap and dont forget to wash your eyes with luke warm water. Avoid using digital screen until you feel better.
\end{Verbatim}
\end{textbox}

\subsection{Bài báo về Chatbot hỗ trợ mua sắm trực tuyến}
Đây là bài báo có tên \textit{SuperAgent: A Customer Service Chatbot
for E-commerce Websites} \cite{superagent}. Trong bài báo này, họ
giới thiệu SuperAgent, một Chatbot dịch vụ khách hàng, sử dụng dữ liệu
thương mại điện tử quy mô lớn và công khai. SuperAgent tận dụng dữ liệu
từ mô tả sản phẩm trong trang cũng như nội dung do người dùng tạo từ
các trang web thương mại điện tử. Ngoài ra, SuperAgent sinh câu phản hồi
dựa trên bốn mô hình chạy song song, bao gồm các bộ câu hỏi và trả lời
(QA) thực tế, bộ tìm kiếm QA thường gặp, bộ QA văn bản định hướng ý kiến,
và mô hình cuộc trò chuyện chit-chat.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{thesis/chatbot/congtrinh/img/superagent.png}
    \caption{Kiến trúc tổng quát của hệ thống SuperAgent}
    \label{fig:superagent}
\end{figure}

Hình \ref{fig:superagent} mô tả tổng quan hệ thống của SuperAgent.
Như hình cho thấy, khi trang sản phẩm được truy cập lần đầu tiên,
SuperAgent thu thập các dữ liệu thông tin sản phẩm (PI), bộ câu hỏi
và trả lời (QA) và phản hồi của khách hàng (CR) từ trang web. Ưu điểm
của mẫu thiết kế này là họ không cần triển khai trình thu thập
thông tin cho các trang web. Thay vào đó, khi người dùng truy cập
trang, SuperAgent sẽ được thông báo vì có tiện ích bổ sung được
liên kết với mỗi trang web. Do đó, SuperAgent mang lại rất ít lượt
tải web bổ sung cho các trang web đã được lưu trữ. Bên cạnh đó,
kiến trúc này giúp cho việc cập nhật dữ liệu rất dễ thực hiện,
trong đó các trang được truy cập thường xuyên sẽ được cập nhật
thường xuyên và ngược lại. Với một truy vấn đầu vào từ khách hàng,
các công cụ khác nhau sẽ được xử lý song song. Nếu một trong ba câu
trả lời từ ba công cụ đầu tiên có độ tin cậy cao, thì chatbot sẽ
trả về câu trả lời từ phản hồi. Nếu không, công cụ trò chuyện sẽ
tạo ra một câu trả lời từ các nhóm câu trả lời được phép xác định
trước.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.45\textwidth]{thesis/chatbot/congtrinh/img/superagentdialog.png}
    \caption{Một mẫu hội thoại của SuperAgent}
    \label{fig:superagentdialog}
\end{figure}

Hình \ref{fig:superagentdialog} cho thấy một tình huống điển hình
khi một khách hàng yêu cầu SuperAgent giúp đỡ. Khi khách hàng mở
cửa sổ trò chuyện trong trình duyệt web, SuperAgent đầu tiên sẽ
phát hiện sản phẩm nào đang được truy cập. Sau đó, SuperAgent tự
giới thiệu và xác nhận rằng khách hàng đang ghé thăm sản phẩm.
Khách hàng có thể chào hỏi SuperAgent hoặc hỏi các câu hỏi cụ thể.
Như hình \ref{fig:superagentdialog} cho thấy, SuperAgent có thể
trả lời các câu hỏi sự thật (Fact QA) bằng cách sử dụng thông tin
sản phẩm trong trang, thực hiện tìm kiếm câu hỏi thường gặp (FAQ
Search) từ các cặp QA của khách hàng, lấy câu trả lời QA từ đánh giá
của khách hàng và cuối cùng là chào hỏi khách hàng bằng cách sử dụng
công cụ trò chuyện chit-chat. Các hộp thoại được điều phối bởi
công cụ meta để các truy vấn khác nhau chuyển đến các công cụ
tương ứng. Vì các trang web thương mại điện tử được cập nhật
thường xuyên và nội dung mới do người dùng tạo liên tục xuất hiện,
SuperAgent cũng cập nhật dữ liệu và mô hình định kỳ theo tần suất
truy cập của khách hàng.

\subsection{Bài báo về Chatbot hỗ trợ sân bay}
Đây là bài báo có tên \textit{Design and implementation of an airport
chatbot} \cite{airport}. Trong bài báo này, họ mô tả động lực và
quá trình phát triển của một Chatbot nhằm cung cấp thông tin và hỗ trợ
cho khách du lịch trực tiếp bên trong nhà ga Sân bay Venice hoặc bằng
các giao diện gián tiếp, chẳng hạn như ứng dụng di động hoặc trang web.

Để phát triển Chatbot, họ quyết định dựa trên một nền tảng được
cung cấp bởi một công ty công nghệ lớn: Microsoft Azure Bot Service.
Tất cả các dịch vụ cloud và dịch vụ máy chủ cho trang web và quản lý
email đều đã được Microsoft quản lý. Họ sử dụng bộ xử lý ngôn ngữ
tự nhiên để hiểu loại (ý định) và các tham số (thực thể) của câu hỏi
mà người dùng có thể hỏi, bất kể nó được hỏi như thế nào.

Ví dụ, trong Chatbot của họ, câu \enquote{what is the weather like in
Venice?} (Thời tiết ở Venice như thế nào?) được chuyển thành một
đối tượng như ví dụ \ref{exam:airport}, có thể được thao tác bởi
Chatbot.

\renewcommand{\textboxenvname}{Ví dụ}
\begin{textbox}[exam:airport]{Biểu diễn của một câu hỏi}
\begin{Verbatim}[breaklines=true, breakanywhere=true]
{
    intent : "weather",
    parameters : {
        address : {
            city : "Venice"
        },
        date-time : "2019-01-20T12:00:00+02:00"
    }
}
\end{Verbatim}
\end{textbox}

Hệ thống họ phát triển có các chức năng sau:

\begin{itemize}
    \item Câu hỏi thường gặp (FAQ).
    \item Các câu hỏi chung về sân bay do tổng đài thu thập.
    \item Thông tin chuyến bay.
    \item Thông tin giao thông địa phương đến và đi từ sân bay
    (kế hoạch chuyến đi).
    \item Vị trí của các cửa hàng, hoạt động hoặc cổng bên trong
    sân bay.
    \item Thông tin về bãi đậu xe.
    \item Tìm hành lý thất lạc.
    \item Tìm đồ bị mất.
\end{itemize}

Sơ đồ chung của Chatbot được thể hiện trong hình \ref{fig:airportarch}.
LUIS là dịch vụ xử lý như NLP. Nó có giao diện web cho phép tạo ra các
ý định và thực thể nhưng không cung cấp phản hồi trực tiếp. Tích hợp
LUIS cho phép bot hiểu ngôn ngữ tự nhiên, phát hiện lỗi chính tả,
sử dụng nhận dạng giọng nói và nhận ra mục đích của người dùng. QnA
Maker là một dịch vụ API dựa trên đám mây tạo ra một lớp câu hỏi và
câu trả lời tương tự như một cuộc trò chuyện dữ liệu. Các câu hỏi và
câu trả lời được nhập từ nội dung bán cấu trúc (semi-structure),
chẳng hạn như tài liệu thường gặp, các đường dẫn và hướng dẫn sử dụng
sản phẩm. Chatbot phải giao tiếp với các dịch vụ cơ sở dữ liệu và API
của sân bay để trả lời các câu hỏi cụ thể liên quan đến sân bay.

Các câu hỏi của người dùng được quản lý và phân tích bởi bộ điều phối
(dispatcher) để quyết định xem câu hỏi có yêu cầu phản hồi linh động
hay không, nếu có nó phải được gửi đến LUIS, hoặc câu hỏi tĩnh được
gửi đến bộ tạo câu hỏi và trả lời (QnA). Quyền truy cập vào cơ sở
hạ tầng sân bay nội bộ và các lệnh gọi API bên ngoài được thực hiện
trực tiếp bởi dịch vụ bot Azure.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{thesis/chatbot/congtrinh/img/airportarch.png}
    \caption{Sơ đồ tổng quát của Chatbot sân bay}
    \label{fig:airportarch}
\end{figure}

\subsection{Bài báo về Chatbot hỗ trợ dịch vụ cung ứng}
Đây là bài báo có tên \textit{E-commerce Distributed Chatbot System}
\cite{commerce}. Trong bài báo này, họ trình bày một hệ thống Chatbot
phân tán cho chuỗi cung ứng. Hệ thống của họ bao gồm một số dịch vụ:
dịch vụ trò chuyện, dịch vụ bot, dịch vụ xử lý ngôn ngữ tự nhiên và
dịch vụ chuỗi cung ứng. Nó sử dụng giao tiếp WebSocket giữa giao diện
người dùng và bot, phân tích truy vấn của người dùng và cung cấp
thông tin về các đơn đặt hàng và nguồn cung cấp đã được truy vấn.

Kiến trúc hệ thống của Chatbot phân tán cho chuỗi cung ứng được
đề xuất trong bài báo như trên hình \ref{fig:commerce}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{thesis/chatbot/congtrinh/img/commerce.png}
    \caption{Kiến trúc hệ thống Chatbot phân tán}
    \label{fig:commerce}
\end{figure}

Hệ thống bao gồm năm dịch vụ con:
\begin{itemize}
    \item Dịch vụ trò chuyện (Chat Service): chịu trách nhiệm về
    giao tiếp WebSocket giữa giao diện người dùng và bot.
    \item Dịch vụ bot (Bot Service): phân tích thông điệp của
    người dùng, xây dựng yêu cầu truy xuất thông tin cần thiết
    và cung cấp cho người dùng một cách dễ hiểu.
    \item Dịch vụ hiểu ngôn ngữ tự nhiên (NLU Service): phân tích
    thông điệp của người dùng, trích xuất thông tin về ý định của
    người dùng và các đối tượng làm phong phú thêm thông tin về
    ý định đó.
    \item Dịch vụ chuỗi cung ứng (Supply Chain Service): chứa
    thông tin về đơn đặt hàng và nguồn cung cấp cho người dùng.
    \item Dịch vụ an ninh (Security Service): chịu trách nhiệm
    về bảo mật thông tin liên lạc qua dịch vụ trò chuyện.
\end{itemize}

Sơ đồ triển khai của hệ thống Chatbot phân tán cho chuỗi cung ứng
dựa trên kiến trúc đề xuất được hiển thị trên hình
\ref{fig:commercediagram}.
Hệ thống được triển khai dưới dạng có tám bộ chứa docker.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{thesis/chatbot/congtrinh/img/commerce_diagram.png}
    \caption{Sơ đồ triển khai của hệ thống Chatbot phân tán}
    \label{fig:commercediagram}
\end{figure}

Đánh giá thử nghiệm của họ đối với hệ thống Chatbot phân tán cho
chuỗi cung ứng được dựa trên hai nhóm mẫu thử nghiệm: mẫu thử nghiệm
tuân theo mẫu dữ liệu đào tạo và mẫu thử nghiệm sử dụng nhiều từ
đồng nghĩa trong truy vấn của người dùng dựa trên ngôn ngữ tự nhiên.

Kết quả thử nghiệm của họ cho thấy khả năng nhận dạng đúng trong 90\%
các câu người dùng thử nghiệm mẫu và tỷ lệ nhận dạng 65\% đối với các
truy vấn của người dùng với các từ đồng nghĩa của các câu đó.

Chất lượng nhận dạng dịch vụ của NLU được tăng thêm lên 83\% đối với
các truy vấn của người dùng khác với các mẫu tham chiếu, bằng cách
đào tạo bổ sung hệ thống NLU với dữ liệu thử nghiệm không được
giải quyết đúng cách.

Ngoài ra, họ còn đánh giá hiệu suất của nó bằng cách sử dụng thử nghiệm
áp lực (stress test) thông qua Gatling. Kết quả thử nghiệm cho thấy rằng
hệ thống có thể xử lý tới 10000 phiên người dùng mà không cần mở rộng
bất kỳ máy chủ nào trong 60 phút. Độ trễ chính của hệ thống đến từ
việc không thể triển khai nhiều kết nối WebSocket cùng một lúc.

\section{Các công trình nghiên cứu liên quan đến Chatbot sử dụng
mô hình học tăng cường}

\subsection{Bài báo về Chatbot sử dụng hành động phân cụm và phần thưởng}
Đây là bài báo có tên \textit{Deep Reinforcement Learning for
Chatbots Using Clustered Actions and Human-Likeness Rewards}
\cite{clustered}. Trong bài báo này, sử dụng các hành động phân cụm
thay vì lượng lớn các hành động và một bộ khen thưởng đơn giản
dựa trên cách cho điểm giống con người thu được từ dữ liệu hội thoại
giữa con người với con người.

Họ huấn luyện các tác nhân học tăng cường sâu (DRL) bằng cách sử dụng
dữ liệu trò chuyện trong văn bản thô - mà không có bất kỳ chú thích
thủ công nào.

Kịch bản học tập của họ như sau:

\begin{itemize}
    \item Lấy một tập dữ liệu về các cuộc hội thoại giữa con người
    với con người ở dạng văn bản thô, tác nhân sẽ đóng vai trò của
    một trong hai người trong cuộc hội thoại, để học cách chọn những
    câu giống người khi tiếp xúc với cả những câu giống người và
    không giống người.
    \item Các tương tác của môi trường-tác nhân bao gồm cả các
    tương tác dữ liệu-tác nhân - không có trình mô phỏng người dùng
    như trong các hệ thống hội thoại hướng tác vụ.
    \item Trong mỗi lượt hội thoại, tác nhân quan sát trạng thái của
    môi trường thông qua mạng nơ-ron học sâu. Mạng này nó mô hình hóa
    một biểu diễn của tất cả các câu được nêu ra trong cuộc hội thoại
    cùng với một tập hợp các câu trả lời của ứng viên hoặc hành động
    của tác nhân (các hành động được phân cụm theo phương pháp của họ).
    \item Sau đó tác nhân chọn một hành động, biểu diễn dựa trên mức
    từ của hành động được gửi đến môi trường.
    \item Tác nhân nhận được lịch sử hội thoại đã được cập nhật và
    phần thưởng cho hành động đó, cho đến khi đáp ứng điều kiện chấm dứt.
\end{itemize}

Quá trình này, được minh họa trong hình \ref{fig:clusterarch} - được
thực hiện lặp đi lặp lại cho đến khi kết thúc một cuộc hội thoại cho
nhiều cuộc hội thoại nếu cần, tức là cho đến khi không có cải thiện
nào nữa về hiệu suất của tác nhân.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{thesis/chatbot/congtrinh/img/clusterarch.png}
    \caption{Kiến trúc hệ thống Chatbot DRL}
    \label{fig:clusterarch}
\end{figure}

Một số đóng góp của bài báo này như sau.

\begin{itemize}
    \item Họ đề xuất huấn luyện các Chatbot bằng cách sử dụng
    phương pháp học tăng cường dựa trên giá trị, bằng cách sử dụng
    không gian hành động bắt nguồn từ phân cụm không giám sát,
    trong đó mỗi cụm hành động là đại diện của một loại ý nghĩa
    (lời chào, câu hỏi xung quanh một chủ đề, phát biểu xung quanh
    một chủ đề, v.v.).
    \item Họ đề xuất một chức năng phần thưởng đơn giản nhưng đầy
    hứa hẹn. Nó dựa trên các cuộc hội thoại giữa con người với
    con người và các cuộc hội thoại nhiễu để học cách đánh giá
    các cuộc hội thoại tốt và xấu.
\end{itemize}

\subsection{Bài báo về hệ thống tạo đối thoại}
Đây là bài báo có tên \textit{Deep Reinforcement Learning for
Dialogue Generation} \cite{generation}. Trong bài báo này, họ
giới thiệu một phương pháp học tập tăng cường (RL), phương pháp này
có thể tối ưu hóa phần thưởng dài hạn do các nhà phát triển hệ thống
thiết kế. Mô hình của họ sử dụng kiến trúc bộ mã hóa giải mã
(encoder-decoder) và mô phỏng cuộc trò chuyện giữa hai tác nhân ảo
để khám phá không gian của các hành động có thể xảy ra trong khi
học cách tối đa hóa phần thưởng mong đợi. Các tham số của bộ
encoder-decoder RNN xác định chính sách (policy) trên một không gian
hành động vô hạn bao gồm tất cả các cách phát biểu có thể có.
Tác nhân tìm hiểu chính sách bằng cách tối ưu hóa phần thưởng
dài hạn do nhà phát triển xác định từ các mô phỏng hội thoại
đang diễn ra bằng cách sử dụng phương pháp gradient chính sách
\cite{gradient}. Do đó, mô hình của họ tích hợp sức mạnh của hệ thống
SEQ2SEQ để học các ý nghĩa ngữ nghĩa cấu thành của lời nói với các
điểm mạnh của học tăng cường trong việc tối ưu hóa cho các mục tiêu
dài hạn trong một cuộc trò chuyện.

Họ mô phỏng các cuộc trò chuyện giữa hai tác nhân ảo và để chúng
thay phiên trò chuyện với nhau, như hình \ref{fig:generation}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{thesis/chatbot/congtrinh/img/generation.png}
    \caption{Mô phỏng đối thoại giữa hai tác nhân}
    \label{fig:generation}
\end{figure}

Quá trình mô phỏng diễn ra như sau:

\begin{itemize}
    \item Ở bước đầu tiên, một thông báo từ tập huấn luyện được đưa
    đến tác nhân đầu tiên. Tác nhân mã hóa thông điệp đầu vào thành
    biểu diễn vec-tơ.
    \item Sau đó, bắt đầu giải mã để tạo ra đầu ra phản hồi.
    \item Kết hợp đầu ra ngay lập tức từ tác nhân đầu tiên với
    lịch sử đối thoại, tác nhân thứ hai cập nhật trạng thái
    bằng cách mã hóa lịch sử đối thoại thành một biểu diễn.
    \item Sau đó, sử dụng bộ giải mã RNN để tạo ra các phản hồi.
    \item Phản hồi được trả lại cho tác nhân đầu tiên và quá trình
    này được lặp đi lặp lại.
\end{itemize}

Kết quả thử nghiệm được lấy mẫu ở hình \ref{fig:generationdialog}
chứng minh rằng cách tiếp cận của họ thúc đẩy một cuộc đối thoại
bền vững hơn và quản lý để tạo ra nhiều phản hồi tương tác hơn
so với các mô hình SEQ2SEQ tiêu chuẩn được đào tạo bằng cách
sử dụng mục tiêu MLE.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{thesis/chatbot/congtrinh/img/generationdialog.png}
    \caption{Kết quả thử nghiệm của hai mô hình}
    \label{fig:generationdialog}
\end{figure}

Cột bên trái: Mô phỏng đối thoại giữa hai tác nhân sử dụng bộ
mã hóa-giải mã LSTM 4 lớp được đào tạo trên tập dữ liệu
OpenSubtitles. Lượt đầu tiên (chỉ số 1) được nhập bởi các tác giả.
Sau đó, hai tác nhân thay phiên nhau trò chuyện, lấy đầu vào cho lượt
tạo trước của tác nhân kia. Cột Bên phải: Cuộc đối thoại được mô phỏng
bằng cách sử dụng mô hình học tập tăng cường được đề xuất. Mô hình mới
có nhiều cách nói hướng tới tương lai hơn (những câu hỏi như
\enquote{Why are you asking?} và những lời đề nghị như
\enquote{I'll come with you} giúp cuộc hội thoại diễn biến lâu hơn
trước khi rơi vào hố đen (black holes).

\subsection{Bài báo về Chatbot FAQ}
Đây là bài báo có tên \textit{Self-improving Chatbots based on
Reinforcement Learning} \cite{selfimproving}. Trong bài báo này,
họ giới thiệu mô hình học tăng cường (RL) cho các Chatbot tự
cải thiện, nhắm mục tiêu cụ thể đến các Chatbot dạng câu hỏi
thường gặp (FAQ).

Mô hình này không nhằm mục đích xây dựng hệ thống hội thoại từ đầu
mà nhằm tận dụng dữ liệu từ các cuộc trò chuyện của người dùng để
cải thiện hiệu suất Chatbot. Cốt lõi của phương pháp tiếp cận của họ
là mô hình điểm số, được đào tạo để tính điểm các câu trả lời của
Chatbot dựa trên phản hồi của người dùng. Điểm số được dự đoán bởi
mô hình này được sử dụng làm phần thưởng cho tác nhân. Việc học
chính sách diễn ra ngoại tuyến, nhờ vào trình mô phỏng người dùng
được cung cấp các câu thoại từ cơ sở dữ liệu FAQ. Học chính sách
được triển khai bằng cách sử dụng tác nhân Deep Q-Network (DQN) với
tính năng thăm dò tham lam (epsilon-greedy), được điều chỉnh để đưa
vào một cách hiệu quả các câu trả lời dự phòng cho các câu hỏi
ngoài phạm vi.

Kiến trúc mô hình được minh họa trong hình \ref{fig:selfimprovingarch}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{thesis/chatbot/congtrinh/img/selfimproving_arch.png}
    \caption{Kiến trúc của mô hình Chatbot FAQ}
    \label{fig:selfimprovingarch}
\end{figure}

Các thành phần khác nhau của mô hình bao gồm:
\begin{itemize}
    \item Bộ hiểu ngôn ngữ tự nhiên (NLU), được sử dụng để huấn luyện
    tác nhân trong giai đoạn khởi động.
    \item Bộ mô phỏng người dùng (User Simulator), trích xuất
    ngẫu nhiên câu thoại của người dùng từ cơ sở dữ liệu về
    trải nghiệm người dùng.
    \item Mô hình điểm số (Score Model) được huấn luyện trên cuộc
    trò chuyện của người dùng với phản hồi và tác nhân dựa trên
    mạng Deep Q-Network (DQN).
\end{itemize}

Tác nhân DQN ban đầu được huấn luyện ngoại tuyến trong giai đoạn
khởi động với NLU. Mô hình điểm số cũng được huấn luyện ngoại tuyến
với dữ liệu từ các cuộc trò chuyện của người dùng thực. Trong
vòng lặp học tăng cường, trạng thái người dùng (lời phát biểu của
người dùng) được cung cấp bởi trình mô phỏng người dùng, hành động
(phản hồi chatbot) được cung cấp bởi tác nhân DQN và phần thưởng
được cung cấp bởi mô hình điểm. Mỗi tuple $(s_t, a_t, r_t)$ cung cấp
bộ đệm phát lại trải nghiệm (experience replay), được sử dụng để
huấn luyện lại DQN sau $n_{episodes}$ số lượt, là một tham số có thể
điều chỉnh được.

Tiềm năng của phương pháp tiếp cận của họ được thể hiện trên một
trường hợp nhỏ được trích xuất từ một Chatbot doanh nghiệp. Nó
cho thấy sự gia tăng hiệu suất từ tỷ lệ thành công 50\% ban đầu
lên 75\% trong 20-30 epoch huấn luyện.

\subsection{Chuỗi bài hướng dẫn huấn luyện Chatbot hướng mục tiêu
sử dụng học tăng cường}
\label{subsec:training}
Đây là chuỗi bài hướng dẫn \cite{traininggochatbot} được thực hiện
bởi một kênh nổi tiếng trên diễn đàn Medium - Towards Data Science.
Điểm nổi bật của chuỗi bài này là tác giả đã xây dựng được một
kiến trúc hệ thống học tăng cường (Reinforcement Learning) khá
hoàn thiện, áp dụng cho bài toán tư vấn có mục tiêu cụ thể. Đặc biệt,
có sử dụng hệ thống giả lập người dùng (User Simulator) với một số
luật đơn giản để giúp hệ thống học tăng cường có thể học được nhanh
hơn rất nhiều thay vì phải cần người thật tương tác. Những kiến thức
đó được tác giả vận dụng từ một bài báo \cite{endtoend} của nhóm
nghiên cứu đến từ phòng nghiên cứu của Microsoft, Hoa Kỳ. Cụ thể,
kiến trúc mà tác giả đề cập tới bao gồm bốn phần chính là
\textit{Agent} (tác nhân - đối tượng sẽ được huấn luyện để ra
quyết định), \textit{Dialog State Tracker} (đối tượng quản lý
trạng thái hội thoại), \textit{User Simulator} (đối tượng giả lập
người dùng - mục đích giúp quá trình huấn luyện nhanh chóng hơn) và
\textit{EMC - Error Model Controller} (mô phỏng lỗi - giúp tác nhân
học hiệu quả hơn).

Bài toán mà tác giả nêu ra trong bài viết của mình là tư vấn chọn vé
xem phim. Dữ liệu là các thông tin của xuất phim và được lưu dưới ở
dạng các cặp khóa - giá trị như biểu diễn ở ví dụ \ref{exam:dbmovie}.

\renewcommand{\textboxenvname}{Ví dụ}
\begin{textbox}[exam:dbmovie]{Dữ liệu thông tin của các xuất phim}
\begin{Verbatim}[breaklines=true, breakanywhere=true]
0L: {'city': 'hamilton', 'theater': 'manville 12 plex', 'zip': '08835', 'critic_rating': 'good', 'genre': 'comedy', 'state': 'nj', 'starttime': '10:30am', 'date': 'tomorrow', 'moviename': 'zootopia'}
897L: {'city': 'seattle', 'theater': 'pacific place 11', 'moviename': 'how to be single', 'zip': '98101', 'critic_rating': 'top', 'date': 'tonight', 'state': 'washington', 'other': 'date', 'starttime': '9', 'theater_chain': 'amc', 'genre': 'romance'}
\end{Verbatim}
\end{textbox}

Các khóa như \enquote{0L} hay \enquote{897L} là khóa định danh của
từng xuất phim có kiểu dữ liệu số nguyên và giá trị của nó cũng ở
dạng các cặp khóa - giá trị (một kiểu \textit{dictionary} trong
\textit{python}) có chứa các thông tin (city, theater, zip, v.v.).
Các xuất phim không có số lượng các thông tin giống nhau và các
giá trị của thông tin cũng khác nhau.

Ngoài ra, họ còn có một loại dữ liệu nữa là từ điển (database
dictionary) chứa tất cả các giá trị có thể có của từng thông tin với
mục đích là dùng cho bộ \textit{EMC} để tạo ra lỗi, cấu trúc được
biểu diễn như ở ví dụ \ref{exam:dictmovie}.

\renewcommand{\textboxenvname}{Ví dụ}
\begin{textbox}[exam:dictmovie]{Từ điển của các thông tin xuất phim}
\begin{Verbatim}[breaklines=true, breakanywhere=true]
'city': ['hamilton', 'manville', 'bridgewater', 'seattle', 'bellevue', 'birmingham', 'san francisco', 'portland', ...]
'theater': ['manville 12 plex', 'amc dine-in theatres bridgewater 7', 'bridgewater', 'every single theatre', ...]
\end{Verbatim}
\end{textbox}

Loại dữ liệu thứ ba được tác giả đề cập tới là danh sách mục tiêu
người dùng (user goal) chứa tất cả mục tiêu có thể có của người dùng
khi họ bắt đầu một cuộc hội thoại với Chatbot. Dữ liệu này sẽ được
\textit{User Simulator} sử dụng trong quá trình huấn luyện
\textit{agent}, cấu trúc bao gồm:

\begin{itemize}
    \item \textit{inform slots}: các thông tin người dùng sẽ cung cấp
    cho \textit{agent}.
    \item \textit{request slots}: các thông tin người dùng yêu cầu
    nhận được từ \textit{agent}.
\end{itemize}

\textit{Inform slots} và \textit{request slots} có thể có giá trị
hoặc rỗng. Cấu trúc được biểu diễn như ở ví dụ \ref{exam:goalmovie}.

\renewcommand{\textboxenvname}{Ví dụ}
\begin{textbox}[exam:goalmovie]{Mục tiêu người dùng của hệ thống tư vấn chọn vé xem phim}
\begin{Verbatim}[breaklines=true, breakanywhere=true]
{'request_slots': {'date': 'UNK', 'theater': 'UNK'}, 'inform_slots': {'numberofpeople': '4', 'moviename': 'zootopia', 'starttime': 'matinee'}}
{'request_slots': {'theater': 'UNK'}, 'inform_slots': {'city': 'la', 'numberofpeople': '2', 'distanceconstraints': 'downtown', 'video_format': '3d', 'starttime': '7pm', 'date': 'tomorrow', 'moviename': 'creed'}}
\end{Verbatim}
\end{textbox}

Một khái niệm được đề cập xuyên suốt gọi là \textit{action}.
\textit{Action} mô tả một hành động và dựa trên nó, ta có thể sinh ra
câu phản hồi. Hệ thống không làm việc trực tiếp với câu dưới dạng
ngôn ngữ tự nhiên mà thông qua \textit{action}. Một \textit{action}
sẽ có \textit{inform slots} và \textit{request slots} giống
\textit{user goal} như đã nêu ở trên đồng thời có thêm
\textit{intent} - ý định của người dùng hoặc của \textit{agent}
ứng với mỗi câu thoại diễn ra trong hội thoại. Với bài toán tư vấn
vé xem phim, tác giả đã định nghĩa các loại \textit{intent} như:

\begin{itemize}
    \item \textbf{Inform:} cung cấp những điều kiện ràng buộc,
    thông tin được trình bày trong \textit{inform slots}.
    \item \textbf{Request:} yêu cầu giá trị cho các thông tin được
    trình bày trong \textit{request slots}.
    \item \textbf{Thanks:} chỉ thực hiện bởi người dùng, thể hiện cho
    \textit{agent} biết rằng nó đã làm gì đó tốt hoặc người dùng đã
    sẵn sàng kết thúc cuộc hội thoại.
    \item \textbf{Match Found:} chỉ thực hiện bởi \textit{agent},
    thông báo cho người dùng biết rằng nó đã tìm được thông tin
    thỏa mãn các điều kiện ràng buộc của người dùng.
    \item \textbf{Reject:} chỉ thực hiện bởi người dùng, báo cho
    \textit{agent} biết rằng thông tin nó vừa thông báo không
    thỏa mãn yêu cầu ràng buộc của người dùng.
    \item \textbf{Done:} \textit{agent} sử dụng để báo rằng nó đã
    hoàn thành mục tiêu hội thoại. Người dùng sử dụng \textit{intent}
    này để kết thúc hội thoại.
\end{itemize}

Khái niệm đi kèm với \textit{action} là \textit{state} - trạng thái
của cuộc hội thoại. Nó đóng vai trò là đầu vào cho \textit{agent} để
chọn ra một \textit{action} phù hợp nhất. \textit{State} thực chất là
một ma trận mã hóa toàn bộ lịch sử hội thoại từ lúc bắt đầu cho tới
thời điểm hiện tại.

Hình \ref{fig:trainrefer} mô tả một vòng huấn luyện của hệ thống này
sẽ được diễn ra. Cụ thể:

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{thesis/chatbot/congtrinh/img/train_refer.png}
    \caption{Kiến trúc tổng quát của mô hình RL agent}
    \label{fig:trainrefer}
\end{figure}

\begin{itemize}
    \item \textbf{Bước 1:} Lấy ra \textit{state} - trạng thái hiện tại từ
    \textit{State Tracker}, \textit{state} này có thể là \textit{state}
    khởi tạo nếu như vừa bắt đầu hội thoại hoặc là \textit{state} của
    toàn bộ cuộc hội thoại giữa người dùng và Chatbot. \textit{State}
    sau khi được lấy ra sẽ làm đầu vào (input) cho \textit{agent} ở
    bước tiếp theo.
    \item \textbf{Bước 2:} \textit{Agent} sau khi nhận được input từ
    bước trước sẽ sinh ra \textit{action} và gửi ngược về lại
    \textit{State Tracker}. \textit{Action} lúc này ở dạng thô, chưa
    kèm thông tin cụ thể. Nó sẽ được \textit{State Tracker} cập nhật
    thông tin sau khi thực hiện truy vấn lên cơ sở dữ liệu. Đồng thời
    \textit{State Tracker} cũng sẽ cập nhật lại trạng thái của hội thoại.
    \item \textbf{Bước 3:} \textit{Action} sau khi được cập nhật
    đầy đủ thông tin sẽ được gửi cho \textit{User Simulator}.
    \textit{User Simulator} sẽ dựa vào các luật đã được quy định trước
    để sinh ra \textit{action} (có cấu trúc tương tự \textit{action}
    của \textit{agent} ở bước trước), kèm theo \textit{reward}
    (điểm thưởng) và tín hiệu success (thành công) để giúp
    \textit{agent} có thể tự điều chỉnh hành vi để học.
    \item \textbf{Bước 4:} \textit{Action} của người dùng ở bước
    trước đó sẽ được đưa qua \textit{EMC}, mục đích là tạo ra các lỗi
    mà người dùng thật hay mắc phải, giúp \textit{agent} có hành vi
    chính xác và tự nhiên hơn khi chạy ở thực tế.
    \item \textbf{Bước 5:} \textit{Action} ở bước trước sẽ tiếp tục
    được gửi đi đến \textit{State Tracker} và được cập nhật thông tin
    cụ thể tương tự ở bước 2. Đồng thời \textit{State Tracker} cũng
    cập nhật trạng thái của nó.
    \item \textbf{Bước 6:} Trạng thái tiếp theo được lấy từ
    \textit{State Tracker} và quay lại giống bước 1.
\end{itemize}

\section{Kết luận}
Hiện nay, có rất nhiều nghiên cứu, công trình liên quan đến xây dựng
một Chatbot tư vấn khách hàng trong nhiều lĩnh vực cũng như các
nghiên cứu cụ thể liên quan đến mô hình sử dụng học tăng cường như
đã trình bày ở một số công trình ở trên.

Trong đó, các công trình xây dựng Chatbot cho các dịch vụ tư vấn
sử dụng các phương pháp đa dạng, từ đơn giản như sử dụng cấu trúc
ngôn ngữ và so trùng cho đến áp dụng các bộ xử lý ngôn ngữ tự nhiên,
huấn luyện mô hình hay để tiết kiệm nguồn lực và chi phí sử dụng
các nền tảng sẵn có. Việc này cũng tùy thuộc vào lĩnh vực của
Chatbot hoạt động.

Các hướng tiếp cận sử dụng mô hình học tăng cường cũng được áp dụng
trên nhiều lĩnh vực khác nhau. Kết quả của những nghiên cứu trên
cũng thể hiện được điểm mạnh của mô hình này. Các tác nhân có các
phản hồi linh hoạt hơn, với cơ chế tự học cũng giúp nó không
giới hạn khả năng. Lý giải tại sao giải thuật học tăng cường được
áp dụng mạnh mẽ trong các hệ thống Chatbot. Vì vậy trong luận văn
này cũng đã áp dụng phương pháp này. Cụ thể, đề tài tham khảo một
kiến trúc huấn luyện mô hình học tăng cường hướng mục tiêu được
trình bày ở mục \ref{subsec:training}.
